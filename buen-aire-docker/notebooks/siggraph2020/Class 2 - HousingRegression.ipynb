{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousingRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OObB3XxZxY5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "#----------DATA READING \n",
        "filename = 'https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv'\n",
        "# read file\n",
        "csv_data = pd.read_csv(filename, sep=',')\n",
        "\n",
        "#----------DATA CLEANUP \n",
        "# drop bad data\n",
        "clean_data = csv_data.dropna() \n",
        "\n",
        "# normalize the data\n",
        "norm_data = (clean_data-clean_data.min())/(clean_data.max()-clean_data.min()) \n",
        "\n",
        "print(norm_data.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEKhBHNuw3X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(clean_data.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMjZrTC_E_2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------TRAIN/TEST SPLIT \n",
        "train_data = norm_data.sample(frac=0.8) # take 80% randomly from the data for training\n",
        "test_data = norm_data.drop(train_data.index) # reserve the rest for testing\n",
        "\n",
        "# separate out the y (results) from x (features)\n",
        "x_train = train_data.drop('median_house_value', axis=1)\n",
        "y_train = train_data['median_house_value']\n",
        "\n",
        "# separate out the y (results) from x (features)\n",
        "x_test = test_data.drop('median_house_value', axis=1)\n",
        "y_test = test_data['median_house_value']\n",
        "\n",
        "print('Training Data\\n', x_train.describe().transpose())\n",
        "print('Test Data\\n', x_test.describe().transpose())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daUR1_Wcbzc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(x_train.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGLNw9naGBSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------MODEL BUILDING\n",
        "num_params = len(x_train.keys())\n",
        "print(num_params)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer([num_params], name=\"Input_Layer\"),\n",
        "    tf.keras.layers.Dense(32, activation='relu', name=\"dense_01\"),\n",
        "    tf.keras.layers.Dense(32, activation='relu', name=\"dense_02\"),\n",
        "    # 1 node in the output for the median_house_vale\n",
        "    tf.keras.layers.Dense(1, name=\"Output_Layer\")\n",
        "  ])\n",
        "\n",
        "learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate),\n",
        "              # loss function to minimize\n",
        "              loss='mse',\n",
        "              # list of metrics to monitor\n",
        "              metrics=['mae',])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzgjOeF1eLos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9QFRFpdGFV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit/Train model on training data\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=16,\n",
        "                    epochs=10,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGyCDw3rGp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "16*680"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es_jAzhSGNIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------MONITOR\n",
        "# Plot training & validation loss values\n",
        "fig = plt.figure(figsize=(12,9))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validate'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Gwuyq8GSVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------EVALUATE\n",
        "loss, mae = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Loss:', loss, 'MAE:', mae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm-8h-oMGZ-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------PREDICT\n",
        "p_test = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ7zZV7OGe8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------PLOT True Values vs. Predictions\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(y_test, p_test)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [0, 1]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "# draw a diagonal line for comparison\n",
        "plt.plot(lims, lims)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYu5wSkXFxeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------PLOT the distribution of errors\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "error = p_test.flatten() - y_test\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
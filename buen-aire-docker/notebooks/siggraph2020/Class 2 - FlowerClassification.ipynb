{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowerClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OObB3XxZxY5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "#----------DATA READING \n",
        "filename = 'https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv'\n",
        "# read file\n",
        "csv_data = pd.read_csv(filename, sep=',')\n",
        "print(csv_data.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivPeG6AnuH7C",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.tensorflow.org/images/iris_three_species.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm-Ryu38Zbu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n",
        "#----------DATA CLEANUP \n",
        "csv_data.columns = column_names # new_header #set the header row as the data header\n",
        "print(csv_data.head()) \n",
        "# look at simple data statistics\n",
        "print(csv_data.describe().transpose())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9UNOs6phj1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot of all features agains each other\n",
        "sns.pairplot(csv_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZwLp2FpnpQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "sns.pairplot(csv_data, hue='species') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMjZrTC_E_2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------TRAIN/TEST SPLIT \n",
        "train_data = csv_data.sample(frac=0.8) # take 80% randomly from the data for training\n",
        "test_data = csv_data.drop(train_data.index) # reserve the rest for testing\n",
        "\n",
        "# separate out the y (results) from x (features) for training\n",
        "x_train = train_data.drop('species', axis=1)\n",
        "y_train = train_data['species']\n",
        "# normalize the training data\n",
        "x_train = (x_train-x_train.min())/(x_train.max()-x_train.min())\n",
        "\n",
        "# separate out the y (results) from x (features) testing\n",
        "x_test = test_data.drop('species', axis=1)\n",
        "y_test = test_data['species']\n",
        "# normalize the test data\n",
        "x_test = (x_test-x_test.min())/(x_test.max()-x_test.min()) \n",
        "\n",
        "print('Training Data\\n', x_train.describe().transpose())\n",
        "print('Test Data\\n', x_test.describe().transpose())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGLNw9naGBSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------MODEL BUILDING\n",
        "num_params = len(x_train.keys())\n",
        "print(num_params)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer([num_params], name=\"Input_Layer\"),\n",
        "    tf.keras.layers.Dense(32, activation='relu', name=\"dense_01\"),\n",
        "    tf.keras.layers.Dense(32, activation='relu', name=\"dense_02\"),\n",
        "    # 3 nodes in the output for 'species'\n",
        "    tf.keras.layers.Dense(3, name=\"Output_Layer\")\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              # loss function to minimize\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              # list of metrics to monitor\n",
        "              metrics=['acc',])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbOqOdSLkOfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------SANITY CHECK\n",
        "# take an example batch and try to predict (we haven't trained yet!)\n",
        "example_batch = x_train[:10]\n",
        "# this gives the log likelihood of the the classes\n",
        "example_result_log = model.predict(example_batch)\n",
        "print('Likelihood', example_result_log)\n",
        "# this gives the probabilities of the classes (should sum up to 1)\n",
        "example_result_prob = tf.nn.softmax(example_result_log).numpy()\n",
        "# these values should be similar and equal to (1/3), because we haven't trained yet and weights are random\n",
        "print('Probabilities', example_result_prob)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9QFRFpdGFV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit/TRAIN model on training data\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=4,\n",
        "                    epochs=10,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es_jAzhSGNIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------MONITOR\n",
        "# Plot training & validation loss values\n",
        "fig = plt.figure(figsize=(12,9))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validate'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Gwuyq8GSVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------EVALUATE\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Loss:', loss, 'Accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm-8h-oMGZ-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------PREDICT\n",
        "\n",
        "p_test = model.predict(x_test) # get the log likelihoods\n",
        "p_test_probabs = tf.nn.softmax(p_test).numpy() # convert to probabilities\n",
        "p_test_class = np.argmax(p_test_probabs, axis=1) # get the max out of the 3 probabilities\n",
        "print(\"Predicted Class:\", p_test_class, '\\nActuals:\\n', y_test.to_string(index=False))\n",
        "#p_test = model.predict_classes(x_test)\n",
        "#print(p_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ7zZV7OGe8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the confision matrix as heatmap\n",
        "sns.heatmap(tf.math.confusion_matrix(y_test, p_test_class), cmap=\"Blues\", annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}